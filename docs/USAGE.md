# üéÆ Gu√≠a de Uso - StockPrep Pro v2.0

## üöÄ Inicio R√°pido

### **Ejecutar la Aplicaci√≥n**
```bash
# Interfaz moderna (PySide6)
python main.py

# Interfaz cl√°sica (Tkinter)
python main.py --gui tkinter

# Modo l√≠nea de comandos
python main.py --cli
```

## üñ•Ô∏è Interfaz Gr√°fica

### **Pesta√±a Principal**

#### **1. Cargar Modelo**
- Haz clic en **"üß† Cargar Modelo Florence-2"**
- Espera a que el bot√≥n cambie a verde ‚úÖ
- El modelo se carga una sola vez por sesi√≥n

#### **2. Seleccionar Im√°genes**
- **Imagen individual**: Haz clic en **"üñºÔ∏è Seleccionar Imagen"**
- **Carpeta completa**: Haz clic en **"üìÇ Seleccionar Carpeta de Im√°genes"**

#### **3. Configurar Nivel de Detalle**
- **üü¢ M√≠nimo**: Descripci√≥n r√°pida (10-15 palabras)
- **üü° Medio**: Balanceado (20-40 palabras)
- **üî¥ Largo**: Detallado (50+ palabras)

#### **4. Configurar Salida**
- **Carpeta de salida**: Selecciona d√≥nde guardar resultados
- **Renombrar**: Activa para renombrar im√°genes autom√°ticamente

#### **5. Procesar**
- Haz clic en **"üöÄ Procesar Imagen"** o **"üöÄ Procesar X Im√°genes"**
- Observa el progreso en tiempo real
- Los resultados aparecen en el panel derecho

### **Pesta√±a Historial**
- **Ver resultados anteriores**: Todos los procesamientos guardados
- **Actualizar**: Refrescar lista de resultados
- **Limpiar**: Eliminar historial completo

### **Pesta√±a Estad√≠sticas**
- **Procesamiento**: Im√°genes procesadas, tasa de √©xito, tiempo promedio
- **Base de datos**: Registros, tama√±o, √∫ltima actualizaci√≥n

## üíª L√≠nea de Comandos

### **Uso B√°sico**
```python
from src.core.model_manager import Florence2Manager
from src.core.image_processor import ImageProcessor

# Inicializar
manager = Florence2Manager()
manager.cargar_modelo()

# Procesar imagen
processor = ImageProcessor(manager)
result = processor.process_image("imagen.jpg", "largo")

# Mostrar resultados
print(f"Descripci√≥n: {result['caption']}")
print(f"Keywords: {result['keywords']}")
print(f"Objetos: {result['objects']}")
```

### **Procesamiento en Lote**
```python
from src.core.batch_engine import BatchEngine

# Configurar procesamiento en lote
batch = BatchEngine(manager, processor)
batch.process_folder("carpeta_imagenes/", "output/", "largo")
```

### **Configuraci√≥n Personalizada**
```python
# Configurar par√°metros espec√≠ficos
config = {
    "max_new_tokens": 2048,
    "temperature": 0.9,
    "num_beams": 5,
    "length_penalty": 1.3
}

result = processor.process_image("imagen.jpg", "largo", config)
```

## üìä Niveles de Detalle

### **üü¢ M√≠nimo**
```python
# Configuraci√≥n autom√°tica
{
    "max_new_tokens": 256,
    "do_sample": False,
    "num_beams": 2,
    "temperature": 0.7
}
```
**Ideal para**: Procesamiento r√°pido, catalogaci√≥n b√°sica

### **üü° Medio**
```python
# Configuraci√≥n autom√°tica
{
    "max_new_tokens": 512,
    "do_sample": True,
    "num_beams": 3,
    "temperature": 0.8,
    "top_p": 0.9
}
```
**Ideal para**: Descripciones balanceadas, uso general

### **üî¥ Largo**
```python
# Configuraci√≥n autom√°tica
{
    "max_new_tokens": 2048,
    "do_sample": True,
    "num_beams": 5,
    "temperature": 0.9,
    "length_penalty": 1.3,
    "min_length": 50
}
```
**Ideal para**: Descripciones detalladas, an√°lisis profundo

## üìÅ Formatos de Salida

### **Archivos Individuales**
```
output/
‚îú‚îÄ‚îÄ imagen1_caption.txt      # Descripci√≥n completa
‚îú‚îÄ‚îÄ imagen1_keywords.txt     # Keywords (una por l√≠nea)
‚îú‚îÄ‚îÄ imagen1_objects.txt      # Objetos detectados
‚îú‚îÄ‚îÄ imagen1.json            # Resultado completo en JSON
‚îî‚îÄ‚îÄ imagen1_renamed.jpg     # Imagen renombrada (si est√° activado)
```

### **Base de Datos SQLite**
```sql
-- Tabla de im√°genes procesadas
SELECT * FROM imagenes WHERE fecha > '2025-01-01';

-- Estad√≠sticas
SELECT COUNT(*) as total, AVG(LENGTH(caption)) as avg_length 
FROM imagenes;
```

### **Exportaci√≥n Masiva**
```python
from src.output.output_handler_v2 import OutputHandlerV2

handler = OutputHandlerV2()

# Exportar a JSON
handler.export_to_json("output/resultados.json")

# Exportar a CSV
handler.export_to_csv("output/resultados.csv")

# Exportar a XML
handler.export_to_xml("output/resultados.xml")
```

## ‚öôÔ∏è Configuraci√≥n Avanzada

### **Archivo de Configuraci√≥n**
```yaml
# config/settings.yaml
modelo:
  nombre: Florence-2-large-ft-safetensors
  ruta_local: models/Florence-2-large-ft-safetensors
  dtype: float32
  device: auto
  max_memory: 0.9

procesamiento:
  batch_size: 1
  num_workers: 0
  prefetch_factor: 2

salida:
  ruta: output/
  formato: JSON
  exportar_txt: true
  copiar_renombrar: true
  comprimir: false

gui:
  preferida: pyside6
  fallback: tkinter
  tema: win11
  idioma: es
```

### **Variables de Entorno**
```bash
# Configurar ruta del modelo
export FLORENCE2_MODEL_PATH="/ruta/a/tu/modelo"

# Configurar memoria CUDA
export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:512"

# Configurar logging
export STOCKPREP_LOG_LEVEL="DEBUG"
```

## üéØ Casos de Uso Pr√°cticos

### **üì∏ Fot√≥grafo Profesional**
```python
# Procesar portfolio completo
batch = BatchEngine(manager, processor)
batch.process_folder("portfolio/", "catalogado/", "largo")

# Generar metadatos para web
handler = OutputHandlerV2()
handler.export_to_json("portfolio_metadata.json")
```

### **üé® Artista Digital**
```python
# Analizar obra de arte
result = processor.process_image("obra_arte.jpg", "largo")

# Extraer elementos visuales
print("Elementos detectados:")
for obj in result['objects']:
    print(f"- {obj['name']}: {obj['confidence']:.2f}")
```

### **üìö Biblioteca**
```python
# Procesar colecci√≥n completa
batch = BatchEngine(manager, processor)
batch.process_folder("coleccion/", "indexado/", "medio")

# Crear √≠ndice de b√∫squeda
handler = OutputHandlerV2()
handler.create_search_index("indice_busqueda.json")
```

## üîß Optimizaciones de Rendimiento

### **GPU Optimizado**
```python
# Verificar optimizaciones
import torch
print(f"TF32: {torch.backends.cuda.matmul.allow_tf32}")
print(f"cuDNN: {torch.backends.cudnn.benchmark}")

# Configurar memoria
torch.cuda.empty_cache()
torch.backends.cuda.caching_allocator_settings = "max_split_size_mb:512"
```

### **Procesamiento Eficiente**
```python
# Usar procesamiento en lote para m√∫ltiples im√°genes
batch = BatchEngine(manager, processor)
batch.process_folder("imagenes/", "output/", "medio")

# Configurar workers para CPU
batch.set_num_workers(4)
```

## üêõ Soluci√≥n de Problemas

### **Error: "Modelo no cargado"**
```python
# Verificar carga del modelo
if not manager.modelo_cargado:
    manager.cargar_modelo()
```

### **Error: "Memoria insuficiente"**
```python
# Reducir batch size
config = {"batch_size": 1, "max_memory": 0.8}
processor = ImageProcessor(manager, config)
```

### **Error: "CUDA out of memory"**
```python
# Limpiar memoria GPU
torch.cuda.empty_cache()

# Usar CPU como fallback
manager = Florence2Manager(device="cpu")
```

## üìû Soporte

### **Logs de Debug**
```python
import logging
logging.basicConfig(level=logging.DEBUG)

# Los logs se guardan en logs/stockprep.log
```

### **Test de Sistema**
```bash
# Ejecutar tests completos
python test_system.py
python test_gpu_model.py
python test_detail_levels.py
```

---

**¬°Disfruta usando StockPrep Pro v2.0! üöÄ** 