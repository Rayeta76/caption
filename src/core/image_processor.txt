"""
Procesador de imágenes con Florence‑2.

— Revisión junio 2025 —
• Asegura coherencia de **dtype** y **device** con el modelo (float32)
• Mantiene la misma API pública
"""
from pathlib import Path
from typing import Dict, List

import torch
from PIL import Image


class ImageProcessor:
    """Procesa una imagen con Florence‑2 a través de un `Florence2Manager`."""

    def __init__(self, model_manager):
        """`model_manager` debe exponer `.model`, `.processor` y `.model.device`."""
        self.manager = model_manager

    # ------------------------------------------------------------------
    #  API pública
    # ------------------------------------------------------------------
    def procesar_imagen(self, ruta_imagen: str) -> Dict:
        """Devuelve descripción + objetos + metadatos o un dict con `error`."""
        if self.manager.model is None:
            return {"error": "Modelo no cargado", "archivo": Path(ruta_imagen).name}

        try:
            image = Image.open(ruta_imagen).convert("RGB")
            res: Dict[str, torch.Tensor | str | Dict] = {}

            res["descripcion"] = self._generar_descripcion(image, "<MORE_DETAILED_CAPTION>")
            res["objetos"] = self._generar_descripcion(image, "<OD>")

            res["archivo"] = Path(ruta_imagen).name
            res["ruta_completa"] = str(ruta_imagen)
            res["tamaño"] = image.size
            return res

        except Exception as exc:
            return {"error": f"Error al procesar imagen: {exc}", "archivo": Path(ruta_imagen).name}

    # ------------------------------------------------------------------
    #  Descripción / objetos
    # ------------------------------------------------------------------
    def _generar_descripcion(self, image: Image.Image, task_tag: str):
        """Genera texto u objeto detectado conforme a la tag solicitada."""
        # 1. Preparar tensores (always float32 to match model)
        inputs = self.manager.processor(text=task_tag, images=image, return_tensors="pt")
        inputs = inputs.to(self.manager.model.device, dtype=self.manager.model.dtype)

        # 2. Generar salida (sin grad)
        with torch.no_grad():
            gen_ids = self.manager.model.generate(
                input_ids=inputs["input_ids"],
                pixel_values=inputs["pixel_values"],
                max_new_tokens=1024,
                do_sample=False,
                num_beams=3,
            )

        # 3. Decodificar y post‑procesar
        gen_text = self.manager.processor.batch_decode(gen_ids, skip_special_tokens=False)[0]
        parsed = self.manager.processor.post_process_generation(
            gen_text, task=task_tag, image_size=(image.width, image.height)
        )
        # Florence‑2 devuelve dict en OC / OD tareas
        if isinstance(parsed, dict):
            return parsed.get(task_tag, str(parsed))
        return str(parsed)

    # ------------------------------------------------------------------
    #  Keywords simples a partir de descripción / objetos
    # ------------------------------------------------------------------
    def extraer_keywords(self, resultado: Dict) -> List[str]:
        palabras_ignorar = {
            "the","a","an","and","or","but","in","on","at","to","for","of","with","by","is","are","was","were",
            "el","la","los","las","un","una","y","o","pero",
        }

        kws: List[str] = []
        desc = resultado.get("descripcion", "")
        if desc:
            for word in desc.lower().split():
                w = word.strip(".,!?;:")
                if len(w) > 3 and w not in palabras_ignorar:
                    kws.append(w)

        objs = resultado.get("objetos", {})
        if isinstance(objs, dict) and "labels" in objs:
            kws.extend(objs["labels"])

        return list({*kws})[:20]  # máximo 20 únicas
